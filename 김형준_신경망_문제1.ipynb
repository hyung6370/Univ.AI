{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "김형준_신경망_문제1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bKLOXwtKTahf8V06_UwZLl6rL_iB1OFH",
      "authorship_tag": "ABX9TyPVK5h/mRUk/4x2T2FgP3y8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyung6370/Univ.AI/blob/main/%EA%B9%80%ED%98%95%EC%A4%80_%EC%8B%A0%EA%B2%BD%EB%A7%9D_%EB%AC%B8%EC%A0%9C1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiZaOYdekasc",
        "outputId": "46aec372-34f9-466d-ecf2-aaf0606019a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx0cSFnYcQlK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datetime import datetime      # datetime.now() 를 이용하여 학습 경과 시간 측정\n",
        "\n",
        "def sigmoid(x):         # sigmoid 함수\n",
        "    return 1 / (1+np.exp(-x))\n",
        "\n",
        "def cross_entropy(t, y) :\n",
        "    delta = 1e-7    # log 무한대 발산 방지\n",
        "    return -np.sum(t*np.log(y+delta) + (1-t)*np.log((1-y)+delta))    \n",
        "\n",
        "def numerical_derivative(f, x):      # 수치미분 함수\n",
        "    delta_x = 1e-4 # 0.0001\n",
        "    grad = np.zeros_like(x)\n",
        "    \n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "    while not it.finished:\n",
        "        idx = it.multi_index        \n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = float(tmp_val) + delta_x\n",
        "        fx1 = f(x) # f(x+delta_x)\n",
        "        \n",
        "        x[idx] = tmp_val - delta_x \n",
        "        fx2 = f(x) # f(x-delta_x)\n",
        "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
        "        \n",
        "        x[idx] = tmp_val \n",
        "        it.iternext()   \n",
        "    return grad\n",
        "\n",
        "class LogicGate:\n",
        "    def __init__(self, gate_name, xdata, tdata):\n",
        "        self.name = gate_name\n",
        "        # 입력 데이터, 정답 데이터 초기화\n",
        "        self.xdata = xdata.reshape(4,2)  # 4개의 입력데이터 x1, x2 에 대하여 batch 처리 행렬\n",
        "        self.tdata = tdata.reshape(4,1)  # 4개의 입력데이터 x1, x2 에 대한 각각의 계산 값 행렬\n",
        "        \n",
        "        # 2층 hidden layer unit : 2개 가정,  가중치 W2, 바이어스 b2 초기화\n",
        "        self.W2 = np.random.rand(2,2)  # weight, 2 X 2 matrix\n",
        "        self.b2 = np.random.rand(2)\n",
        "        \n",
        "        # 3층 output layer unit : 1 개 , 가중치 W3, 바이어스 b3 초기화\n",
        "        self.W3 = np.random.rand(2,1)  # weight, 2 X 1 matrix\n",
        "        self.b3 = np.random.rand(1)\n",
        "                        \n",
        "        # 학습률 learning rate 초기화\n",
        "        self.lr = 1e-2\n",
        "        print(self.name + \" object is created\")\n",
        "            \n",
        "    def feed_forward(self):        # errFunc()함수 대신 feed forward를 통하여 손실함수(cross-entropy) 값 계산\n",
        "        z2 = np.dot(self.xdata, self.W2) + self.b2  # 은닉층의 선형회귀 값\n",
        "        a2 = sigmoid(z2)                            # 은닉층의 출력\n",
        "        z3 = np.dot(a2, self.W3) + self.b3          # 출력층의 선형회귀 값\n",
        "        y = a3 = sigmoid(z3)                        # 출력층의 출력\n",
        "        return cross_entropy(self.tdata, y)         # 출력의 손실값 리턴\n",
        "    \n",
        "    def errValue(self):             # 외부 출력을 위한 손실함수(cross-entropy) 값 계산 \n",
        "        return  self.feed_forward()\n",
        "    \n",
        "    def train(self):            # 수치미분을 이용하여 손실함수가 최소가 될때 까지 학습하는 함수\n",
        "        f = lambda x : self.feed_forward()\n",
        "        start = datetime.now()\n",
        "        for step in range(50001):\n",
        "            self.W2 -= self.lr * numerical_derivative(f, self.W2)\n",
        "            self.b2 -= self.lr * numerical_derivative(f, self.b2)\n",
        "            self.W3 -= self.lr * numerical_derivative(f, self.W3)\n",
        "            self.b3 -= self.lr * numerical_derivative(f, self.b3)\n",
        "            if (step % 2000 == 0):\n",
        "                print(\"Step = {:<5d}\\tError Val = {:.4f}\".format(step, self.errValue()))\n",
        "        print(\"Training time = \", datetime.now() - start)\n",
        "\n",
        "    def predict(self, test):      # query, 즉 미래 값 예측 함수\n",
        "        z2 = np.dot(test, self.W2) + self.b2         # 은닉층의 선형회귀 값\n",
        "        a2 = sigmoid(z2)                             # 은닉층의 출력\n",
        "        z3 = np.dot(a2, self.W3) + self.b3           # 출력층의 선형회귀 값\n",
        "        y = a3 = sigmoid(z3)                         # 출력층의 출력\n",
        "        if y > 0.5:\n",
        "            result = 1  # True\n",
        "        else:\n",
        "            result = 0  # False\n",
        "        return result, y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "층 구성 후, step을 50000까지 늘려 보았고, 손실값이 0.0268까지 나오는 것을 확인하였다."
      ],
      "metadata": {
        "id": "K6K3fWxFl6mq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XOR Gate 객체 생성\n",
        "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
        "tdata = np.array([0, 1, 1, 0])\n",
        "\n",
        "xor = LogicGate(\"XOR\", xdata, tdata)\n",
        "xor.train() \n",
        "\n",
        "test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1], [0.7, 0.3], [0.6, 0.4], [0.5, 0.5], [0.4, 0.6], [0.3, 0.7] ])\n",
        "for data in test_data:\n",
        "    r, y = xor.predict(data)\n",
        "    print(data, \"-->\", r, \"[%.3f]\"%y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5srr1mJcZOa",
        "outputId": "ad0723c7-dda5-4db7-ce7e-2b4ad6018b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR object is created\n",
            "Step = 0    \tError Val = 3.2474\n",
            "Step = 2000 \tError Val = 2.7585\n",
            "Step = 4000 \tError Val = 2.7257\n",
            "Step = 6000 \tError Val = 2.6069\n",
            "Step = 8000 \tError Val = 2.3128\n",
            "Step = 10000\tError Val = 2.0489\n",
            "Step = 12000\tError Val = 1.5950\n",
            "Step = 14000\tError Val = 0.6950\n",
            "Step = 16000\tError Val = 0.3345\n",
            "Step = 18000\tError Val = 0.2092\n",
            "Step = 20000\tError Val = 0.1500\n",
            "Step = 22000\tError Val = 0.1163\n",
            "Step = 24000\tError Val = 0.0946\n",
            "Step = 26000\tError Val = 0.0796\n",
            "Step = 28000\tError Val = 0.0686\n",
            "Step = 30000\tError Val = 0.0603\n",
            "Step = 32000\tError Val = 0.0537\n",
            "Step = 34000\tError Val = 0.0484\n",
            "Step = 36000\tError Val = 0.0440\n",
            "Step = 38000\tError Val = 0.0403\n",
            "Step = 40000\tError Val = 0.0372\n",
            "Step = 42000\tError Val = 0.0346\n",
            "Step = 44000\tError Val = 0.0322\n",
            "Step = 46000\tError Val = 0.0302\n",
            "Step = 48000\tError Val = 0.0284\n",
            "Step = 50000\tError Val = 0.0268\n",
            "Training time =  0:00:35.480320\n",
            "[0. 0.] --> 0 [0.008]\n",
            "[0. 1.] --> 1 [0.994]\n",
            "[1. 0.] --> 1 [0.994]\n",
            "[1. 1.] --> 0 [0.006]\n",
            "[0.7 0.3] --> 1 [0.994]\n",
            "[0.6 0.4] --> 1 [0.994]\n",
            "[0.5 0.5] --> 1 [0.994]\n",
            "[0.4 0.6] --> 1 [0.994]\n",
            "[0.3 0.7] --> 1 [0.994]\n"
          ]
        }
      ]
    }
  ]
}