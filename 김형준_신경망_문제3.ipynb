{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "김형준_신경망_문제3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyung6370/Univ.AI/blob/main/%EA%B9%80%ED%98%95%EC%A4%80_%EC%8B%A0%EA%B2%BD%EB%A7%9D_%EB%AC%B8%EC%A0%9C3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "21913660 김형준(팀장), 21720903 조태식"
      ],
      "metadata": {
        "id": "EvFszz1QVNMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm7KqwtSNbEi",
        "outputId": "ad59ed13-9210-4df0-9725-74b1f9ef0100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkuG-7MlQJQl"
      },
      "source": [
        "import numpy as np\n",
        "from datetime import datetime      # datetime.now() 를 이용하여 학습 경과 시간 측정\n",
        "\n",
        "def sigmoid(x):         # sigmoid 함수\n",
        "    return 1 / (1+np.exp(-x))\n",
        "\n",
        "def cross_entropy(t, y) :\n",
        "    delta = 1e-7    # log 무한대 발산 방지\n",
        "    return -np.sum(t*np.log(y+delta) + (1-t)*np.log((1-y)+delta))    \n",
        "\n",
        "def numerical_derivative(f, x):      # 수치미분 함수\n",
        "    delta_x = 1e-4 # 0.0001\n",
        "    grad = np.zeros_like(x)\n",
        "    \n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "    while not it.finished:\n",
        "        idx = it.multi_index        \n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = float(tmp_val) + delta_x\n",
        "        fx1 = f(x) # f(x+delta_x)\n",
        "        \n",
        "        x[idx] = tmp_val - delta_x \n",
        "        fx2 = f(x) # f(x-delta_x)\n",
        "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
        "        \n",
        "        x[idx] = tmp_val \n",
        "        it.iternext()   \n",
        "    return grad\n",
        "\n",
        "class LogicGate:\n",
        "    def __init__(self, gate_name, xdata, tdata):\n",
        "        self.name = gate_name\n",
        "        # 입력 데이터, 정답 데이터 초기화\n",
        "        self.xdata = xdata.reshape(16,4)  \n",
        "        self.tdata = tdata.reshape(16,2)  \n",
        "        \n",
        "        # 2층 hidden layer unit \n",
        "        self.W2 = np.random.rand(4,10)  \n",
        "        self.b2 = np.random.rand(10)\n",
        "\n",
        "        # 3층 hidden layer unit \n",
        "        self.W3 = np.random.rand(10,5)  \n",
        "        self.b3 = np.random.rand(5)\n",
        "        \n",
        "        # 4층 output layer unit \n",
        "        self.W4 = np.random.rand(5,2)\n",
        "        self.b4 = np.random.rand(2)\n",
        "                        \n",
        "        # 학습률 learning rate 초기화\n",
        "        self.lr = 1e-2\n",
        "        print(self.name + \" object is created\")\n",
        "            \n",
        "    def feed_forward(self):        # errFunc()함수 대신 feed forward를 통하여 손실함수(cross-entropy) 값 계산\n",
        "        z2 = np.dot(self.xdata, self.W2) + self.b2  # 은닉층의 선형회귀 값\n",
        "        a2 = sigmoid(z2)                            # 은닉층의 출력\n",
        "        z3 = np.dot(a2, self.W3) + self.b3          # 출력층의 선형회귀 값\n",
        "        a3 = sigmoid(z3)                            # 출력층의 출력\n",
        "        z4=np.dot(a3,self.W4)+self.b4               # 출력층의 선형회귀 값\n",
        "        y = a4 = sigmoid(z4)                        # 출력층의 출력\n",
        "        return cross_entropy(self.tdata, y)         # 출력의 손실값 리턴\n",
        "    \n",
        "    def errValue(self):             # 외부 출력을 위한 손실함수(cross-entropy) 값 계산 \n",
        "        return  self.feed_forward()\n",
        "    \n",
        "    def train(self):            # 수치미분을 이용하여 손실함수가 최소가 될때 까지 학습하는 함수\n",
        "        f = lambda x : self.feed_forward()\n",
        "        start = datetime.now()\n",
        "        for step in range(100000):\n",
        "            self.W2 -= self.lr * numerical_derivative(f, self.W2)\n",
        "            self.b2 -= self.lr * numerical_derivative(f, self.b2)\n",
        "            self.W3 -= self.lr * numerical_derivative(f, self.W3)\n",
        "            self.b3 -= self.lr * numerical_derivative(f, self.b3)\n",
        "            self.W4 -= self.lr * numerical_derivative(f, self.W4)\n",
        "            self.b4 -= self.lr * numerical_derivative(f, self.b4)\n",
        "            if (step % 2000 == 0):\n",
        "                print(\"Step = {:<5d}\\tError Val = {:.4f}\".format(step, self.errValue()))\n",
        "        print(\"Training time = \", datetime.now() - start)\n",
        "\n",
        "    def predict(self, test):      # query, 즉 미래 값 예측 함수\n",
        "        z2 = np.dot(test, self.W2) + self.b2         # 은닉층의 선형회귀 값\n",
        "        a2 = sigmoid(z2)                             # 은닉층의 출력\n",
        "        z3 = np.dot(a2, self.W3) + self.b3           # 출력층의 선형회귀 값\n",
        "        a3 = sigmoid(z3)                            # 출력층의 출력\n",
        "        z4=np.dot(a3,self.W4)+self.b4               # 출력층의 선형회귀 값\n",
        "        y = a4 = sigmoid(z4)                        # 출력층의 출력\n",
        "        if y[0] > 0.5:\n",
        "            result = 1  # True\n",
        "        else:\n",
        "            result = 0  # False\n",
        "        if y[1]>0.5:\n",
        "            result1=1\n",
        "        else:\n",
        "            result1=0\n",
        "        return result,result1, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKcJ7GPYQr1U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a082bec9-5b05-4d01-cf26-06c1bbe2fb09"
      },
      "source": [
        "# XOR Gate 객체 생성\n",
        "xdata = np.array([ [0,0,0,0], [0,0,0,1], [0,0,1,0], [0,0,1,1], [0,1,0,0], [0,1,0,1], [0,1,1,0], [0,1,1,1], [1,0,0,0], [1,0,0,1], [1,0,1,0], [1,0,1,1], [1,1,0,0], [1,1,0,1], [1,1,1,0], [1,1,1,1]])\n",
        "tdata = np.array([[0,0], [1,1], [1,1], [0,1], [1,1], [0,1], [0,0], [1,1], [1,1], [0,1], [0,0], [1,1], [0,0], [1,1], [1,1], [0,1]])\n",
        "\n",
        "xor = LogicGate(\"XOR\", xdata, tdata)\n",
        "xor.train() \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR object is created\n",
            "Step = 0    \tError Val = 29.9007\n",
            "Step = 2000 \tError Val = 19.9613\n",
            "Step = 4000 \tError Val = 16.7133\n",
            "Step = 6000 \tError Val = 16.4999\n",
            "Step = 8000 \tError Val = 9.3417\n",
            "Step = 10000\tError Val = 8.0662\n",
            "Step = 12000\tError Val = 7.0529\n",
            "Step = 14000\tError Val = 0.9957\n",
            "Step = 16000\tError Val = 0.3539\n",
            "Step = 18000\tError Val = 0.2110\n",
            "Step = 20000\tError Val = 0.1473\n",
            "Step = 22000\tError Val = 0.1113\n",
            "Step = 24000\tError Val = 0.0885\n",
            "Step = 26000\tError Val = 0.0729\n",
            "Step = 28000\tError Val = 0.0615\n",
            "Step = 30000\tError Val = 0.0530\n",
            "Step = 32000\tError Val = 0.0464\n",
            "Step = 34000\tError Val = 0.0411\n",
            "Step = 36000\tError Val = 0.0368\n",
            "Step = 38000\tError Val = 0.0333\n",
            "Step = 40000\tError Val = 0.0303\n",
            "Step = 42000\tError Val = 0.0278\n",
            "Step = 44000\tError Val = 0.0257\n",
            "Step = 46000\tError Val = 0.0238\n",
            "Step = 48000\tError Val = 0.0222\n",
            "Step = 50000\tError Val = 0.0207\n",
            "Step = 52000\tError Val = 0.0195\n",
            "Step = 54000\tError Val = 0.0183\n",
            "Step = 56000\tError Val = 0.0173\n",
            "Step = 58000\tError Val = 0.0164\n",
            "Step = 60000\tError Val = 0.0156\n",
            "Step = 62000\tError Val = 0.0148\n",
            "Step = 64000\tError Val = 0.0141\n",
            "Step = 66000\tError Val = 0.0135\n",
            "Step = 68000\tError Val = 0.0129\n",
            "Step = 70000\tError Val = 0.0124\n",
            "Step = 72000\tError Val = 0.0119\n",
            "Step = 74000\tError Val = 0.0115\n",
            "Step = 76000\tError Val = 0.0110\n",
            "Step = 78000\tError Val = 0.0106\n",
            "Step = 80000\tError Val = 0.0103\n",
            "Step = 82000\tError Val = 0.0099\n",
            "Step = 84000\tError Val = 0.0096\n",
            "Step = 86000\tError Val = 0.0093\n",
            "Step = 88000\tError Val = 0.0090\n",
            "Step = 90000\tError Val = 0.0088\n",
            "Step = 92000\tError Val = 0.0085\n",
            "Step = 94000\tError Val = 0.0083\n",
            "Step = 96000\tError Val = 0.0080\n",
            "Step = 98000\tError Val = 0.0078\n",
            "Training time =  0:26:25.594623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = np.array([[0.5, 0.2, 0.9, 0.3]])\n",
        "for data in test_data:\n",
        "    r, r1, y = xor.predict(data)\n",
        "    print(data, \"-->\", r, r1, \"%.3f %.3f\" % (y[0], y[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtnfG9Etun-W",
        "outputId": "baf34c6d-1197-48be-935b-463f63624814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5 0.2 0.9 0.3] --> 1 1 0.748 1.000\n"
          ]
        }
      ]
    }
  ]
}